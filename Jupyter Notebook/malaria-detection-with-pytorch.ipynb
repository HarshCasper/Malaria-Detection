{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Importing libraries**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nfrom torchvision import datasets, transforms\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import SubsetRandomSampler\nimport torch.nn.functional as F\n\nimport os\nprint(os.listdir(\"../input/cell_images/cell_images/\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Use the GPU if available for computations."},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data Augmentation\n\n* > Using Pytorch transformation function to augment a dataset. I tried different transformations but find these helpful.\n* > All the images are resized to 120 * 120 as an input to custom CNN class.\n* > Applying different transformations like RandomHorizontalFlip( ), RandomRotation( ) etc. There is a 50/50 chance whether it would change the image or not.\n* > Converting images into Pytorch tensors.\n* > Also normalizing them with mean [0.5, 0.5., 0.5] and standard deviation [0.5, 0.5, 0.5]. All tensors are in range of [-1, 1].\n    > It won't increase size of the dataset as transformation performs one by one on images."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transforms = transforms.Compose([transforms.Resize((120, 120)),\n                                       transforms.ColorJitter(0.05),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.RandomVerticalFlip(),\n                                       transforms.RandomRotation(20),\n                                       transforms.ToTensor(), \n                                       transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n                                     ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Loading a images using generic dataloader ImageFolder."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_dir = \"../input/cell_images/cell_images/\"\ntrain_set = datasets.ImageFolder(image_dir, transform=train_transforms)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating a dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_size = 0.2\n\nnum_train = len(train_set)\nindices = list(range(num_train))\nnp.random.shuffle(indices)\n\ntest_split = int(np.floor((test_size) * num_train))\ntest_index, train_index = indices[:test_split - 1], indices[test_split - 1:]\n\ntrain_sampler = SubsetRandomSampler(train_index)\ntest_sampler = SubsetRandomSampler(test_index)\n\ntrain_loader = DataLoader(train_set, sampler=train_sampler, batch_size=104)\ntest_loader = DataLoader(train_set, sampler=test_sampler, batch_size=58)\nprint(\"Images in Test set: {}\\nImages in Train set: {}\".format(len(test_index), len(train_index)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We have images in 2 classes: Infected and Uninfected"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes=['infected','uninfected']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Visualizing some Images..."},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow(img):\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    \nimages, labels = next(iter(train_loader))\n\nfig = plt.figure(figsize=(25, 15))\n\nfor i in range(10):\n    ax = fig.add_subplot(2, 5, i+1, xticks=[], yticks=[], title=classes[labels[i]])\n    imshow(images[i])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CNN class\n* Creating a CNN class as MosquitoNet.\n* It has following layers:\n    * 3 Convolutional layers with MaxPooling (Stride 2)\n    * All 3 convulations are \"Same Convolution with some zero-padding\"\n    * 3 FullyConnected Layers\n* BatchNormalization is used after convulations \n* ReLU is used as a activation function\n* Dropout is used with p = 0.5\n\n* Images are changed from input to output layers in following way:\n    * In Layer 1 : Input: 120 \\* 120 \\* 3, Output: 60 \\* 60 \\* 16\n    * In Layer 2 : Input: 60 \\* 60 \\* 16, Output: 30 \\* 30 \\* 32\n    * In Layer 3 : Input: 30 \\* 30 \\* 32, Output: 15 \\* 15 \\* 64\n    * In FC1 : Input: 14440, Output: 512\n    * In FC2 : Input: 512, Output: 128\n    * In FC3 : Input: 128, Output: 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"class MosquitoNet(nn.Module):\n    \n    def __init__(self):\n        super(MosquitoNet, self).__init__()\n        \n        self.layer1 = nn.Sequential(\n            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(16),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer2 = nn.Sequential(\n            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n            nn.BatchNorm2d(32),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        \n        self.layer3 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n            \n        self.fc1 = nn.Linear(64*15*15, 512)\n        self.fc2 = nn.Linear(512, 128)\n        self.fc3 = nn.Linear(128, 2)\n        self.drop = nn.Dropout2d(0.2)\n        \n    def forward(self, x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = out.view(out.size(0), -1)    # flatten out a input for Dense Layer\n        out = self.fc1(out)\n        out = F.relu(out)\n        out = self.drop(out)\n        out = self.fc2(out)\n        out = F.relu(out)\n        out = self.drop(out)\n        out = self.fc3(out)\n        \n        return out\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Making a model and defining error and optimizing algorithm."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MosquitoNet()\nmodel.to(device)\nerror = nn.CrossEntropyLoss()\nlearning_rate = 0.001\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nprint(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training a Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 20\nbatch_size = 100 \n\nfor epoch in range(num_epochs):\n    train_loss = 0.\n    model.train()    # explictily stating the training\n    \n    for i, (images, labels) in enumerate(train_loader):\n        images, labels = images.to(device), labels.to(device)\n        train = images.view(-1, 3, 120, 120)\n        outputs = model(train)\n        \n        optimizer.zero_grad()\n        loss = error(outputs, labels)\n        loss.backward()    #back-propagation\n        optimizer.step()\n        \n        train_loss += loss.item() * batch_size\n     \n    print(\"Epoch: {}, Loss: {:.4f}\".format(epoch + 1, train_loss / len(train_loader.dataset)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Saving a model in disk"},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), \"model.pt\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Testing a model"},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\nclass_total = [0 for _ in range(2)]\nclass_correct = [0 for _ in range(2)]\nbatch_size = 58\n# Lists used in Confusion Matrix\nactual = []\npredict = []\n\nmodel.eval()    # explicitly stating the testing \nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to (device)\n        \n        actual.append(labels.data.tolist())\n        test = images.view(-1, 3, 120, 120)\n        outputs = model(test)\n        predicted = torch.max(outputs, 1)[1]\n        predict.append(predicted.data.tolist())\n        total += len(labels)\n        correct += (predicted == labels).sum().item()\n        # Calculating classwise accuracy\n        c = (predicted == labels).squeeze()\n        for i in range(batch_size):\n            label = labels[i]\n            class_correct[label] += c[i].item()\n            class_total[label] += 1\n        \nprint(\"Accuracy on the Test set: {:.2f}%\".format(correct * 100 / total))\nprint()\nfor i in range(2):\n    print(\"Accuracy of {} :  {:.2f}%   [{} / {}]\".format(classes[i], class_correct[i] * 100 / class_total[i], \n                                           class_correct[i], class_total[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Calculating a Confusion Matrix"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report\nimport itertools\n\n#flatten out 2D list into 1D\nactual = list(itertools.chain.from_iterable(actual))\npredict = list(itertools.chain.from_iterable(predict))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = confusion_matrix(actual, predict)\nprint(\"Accuracy Score: \")\nprint(\"{:.4f}\".format(accuracy_score(actual, predict)))\nprint()\nprint(\"Report: \")\nprint(classification_report(actual, predict))\nprint()\nprint(\"Confusion Matrix: \")\nprint(pd.DataFrame(results, columns=[\"Predicted No\", \"Predicted Yes\"], index=[\"Actual No\", \"Actual Yes\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Displaying it as a plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.heatmap(results, cmap=\"magma\", annot=True, fmt=\"d\", cbar=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**I've achieved a Test Accuracy of more than 96.5 %. That's not bad. Please suggest improvements. Thank you :) **"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}